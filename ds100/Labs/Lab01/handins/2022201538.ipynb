{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: otter-grader in d:\\anaconda\\lib\\site-packages (5.1.4)\n",
      "Requirement already satisfied: dill in d:\\anaconda\\lib\\site-packages (from otter-grader) (0.3.6)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from otter-grader) (3.1.2)\n",
      "Requirement already satisfied: nbformat in d:\\anaconda\\lib\\site-packages (from otter-grader) (5.7.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from otter-grader) (2.0.3)\n",
      "Requirement already satisfied: PyYAML in d:\\anaconda\\lib\\site-packages (from otter-grader) (6.0)\n",
      "Requirement already satisfied: python-on-whales in d:\\anaconda\\lib\\site-packages (from otter-grader) (0.64.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from otter-grader) (2.31.0)\n",
      "Requirement already satisfied: wrapt in d:\\anaconda\\lib\\site-packages (from otter-grader) (1.14.1)\n",
      "Requirement already satisfied: jupytext in d:\\anaconda\\lib\\site-packages (from otter-grader) (1.15.2)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from otter-grader) (8.0.4)\n",
      "Requirement already satisfied: fica>=0.2.0 in d:\\anaconda\\lib\\site-packages (from otter-grader) (0.3.1)\n",
      "Requirement already satisfied: ipython in d:\\anaconda\\lib\\site-packages (from otter-grader) (8.12.0)\n",
      "Requirement already satisfied: astunparse in d:\\anaconda\\lib\\site-packages (from otter-grader) (1.6.3)\n",
      "Requirement already satisfied: ipywidgets in d:\\anaconda\\lib\\site-packages (from otter-grader) (8.0.4)\n",
      "Requirement already satisfied: ipylab in d:\\anaconda\\lib\\site-packages (from otter-grader) (1.0.0)\n",
      "Requirement already satisfied: nbconvert in d:\\anaconda\\lib\\site-packages (from otter-grader) (6.5.4)\n",
      "Requirement already satisfied: docutils in d:\\anaconda\\lib\\site-packages (from fica>=0.2.0->otter-grader) (0.18.1)\n",
      "Requirement already satisfied: sphinx in d:\\anaconda\\lib\\site-packages (from fica>=0.2.0->otter-grader) (5.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse->otter-grader) (0.38.4)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in d:\\anaconda\\lib\\site-packages (from astunparse->otter-grader) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->otter-grader) (0.4.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in d:\\anaconda\\lib\\site-packages (from ipywidgets->otter-grader) (6.19.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\anaconda\\lib\\site-packages (from ipywidgets->otter-grader) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in d:\\anaconda\\lib\\site-packages (from ipywidgets->otter-grader) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in d:\\anaconda\\lib\\site-packages (from ipywidgets->otter-grader) (3.0.5)\n",
      "Requirement already satisfied: backcall in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (2.15.1)\n",
      "Requirement already satisfied: stack-data in d:\\anaconda\\lib\\site-packages (from ipython->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->otter-grader) (2.1.1)\n",
      "Requirement already satisfied: toml in d:\\anaconda\\lib\\site-packages (from jupytext->otter-grader) (0.10.2)\n",
      "Requirement already satisfied: markdown-it-py>=1.0.0 in d:\\anaconda\\lib\\site-packages (from jupytext->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: mdit-py-plugins in d:\\anaconda\\lib\\site-packages (from jupytext->otter-grader) (0.3.0)\n",
      "Requirement already satisfied: lxml in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (4.12.2)\n",
      "Requirement already satisfied: bleach in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (0.5.13)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (23.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in d:\\anaconda\\lib\\site-packages (from nbconvert->otter-grader) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in d:\\anaconda\\lib\\site-packages (from nbformat->otter-grader) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\anaconda\\lib\\site-packages (from nbformat->otter-grader) (4.17.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas->otter-grader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->otter-grader) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas->otter-grader) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\lib\\site-packages (from pandas->otter-grader) (1.24.3)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=1.5 in d:\\anaconda\\lib\\site-packages (from python-on-whales->otter-grader) (2.3.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from python-on-whales->otter-grader) (4.65.0)\n",
      "Requirement already satisfied: typer>=0.4.1 in d:\\anaconda\\lib\\site-packages (from python-on-whales->otter-grader) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from python-on-whales->otter-grader) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->otter-grader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->otter-grader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->otter-grader) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->otter-grader) (2023.7.22)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (7.4.9)\n",
      "Requirement already satisfied: nest-asyncio in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (1.5.6)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (23.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->otter-grader) (6.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\anaconda\\lib\\site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat->otter-grader) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat->otter-grader) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\anaconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert->otter-grader) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\anaconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert->otter-grader) (305.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda\\lib\\site-packages (from markdown-it-py>=1.0.0->jupytext->otter-grader) (0.1.0)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->otter-grader) (0.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic!=2.0.*,<3,>=1.5->python-on-whales->otter-grader) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in d:\\anaconda\\lib\\site-packages (from pydantic!=2.0.*,<3,>=1.5->python-on-whales->otter-grader) (2.6.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->nbconvert->otter-grader) (2.4)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda\\lib\\site-packages (from bleach->nbconvert->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.3)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.11.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (0.7.12)\n",
      "Requirement already satisfied: imagesize in d:\\anaconda\\lib\\site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: executing in d:\\anaconda\\lib\\site-packages (from stack-data->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\anaconda\\lib\\site-packages (from stack-data->ipython->otter-grader) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in d:\\anaconda\\lib\\site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n",
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: Levenshtein in d:\\anaconda\\lib\\site-packages (0.21.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in d:\\anaconda\\lib\\site-packages (from Levenshtein) (3.3.0)\n",
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install otter-grader\n",
    "!pip install Levenshtein\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"2022201538.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labs01: Exercises with NumPy and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**exercise1:** Array Creation\n",
    "\n",
    "- Make an array `arr1` of shape (10,20) with the array elements filled with 1\n",
    "- Make an array `arr2` of shape (10,20) with the array elements filled with 0\n",
    "- Make an array `arr3` with 100 evenly spaced values between 0 and 2 * pi\n",
    "- Make an array `arr4` which contains the cosine of the corresponding value in x, so arr4[i] = cos(arr3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr1 = np.ones((10,20))\n",
    "arr2 = np.zeros((10,20))\n",
    "arr3 = np.linspace(0, 2 * np.pi, 100)\n",
    "arr4 = np.cos(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>pre_e1</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "pre_e1 results: All test cases passed!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"pre_e1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**exercise2:** Indexing and slicing\n",
    "\n",
    "- Create the following array, call this `arr5`\n",
    "\n",
    "```python\n",
    "        2  7  12  0\n",
    "        3  9  3  4\n",
    "        4  0  1  3\n",
    "```\n",
    "\n",
    "- Get the $2^{nd}$ row of a ([ 3 9 3 4]), call this `arr6`\n",
    "- Get the $3^{rd}$ column of a ([12 3 1]), call this `arr7`\n",
    "- Use `>` to make a mask `arr8` that is true where the elements are greater than 5, like this:\n",
    "\n",
    "```python\n",
    "        False True  True  False\n",
    "        False True  False False\n",
    "        False False False False\n",
    "```\n",
    "\n",
    "- Set all the elements greater than 5 to be equal to 5 with the above mask and call it `arr9    `, to get this:\n",
    "\n",
    "```python\n",
    "        2  5  5  0\n",
    "        3  5  3  4\n",
    "        4  0  1  3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 5 5 0]\n",
      " [3 5 3 4]\n",
      " [4 0 1 3]]\n"
     ]
    }
   ],
   "source": [
    "arr5 = np.array([[2,7,12,0],[3,9,3,4],[4,0,1,3]])\n",
    "arr6 = arr5[1]\n",
    "arr7 = arr5[:,2]\n",
    "arr8 = arr5>5\n",
    "arr9=np.copy(arr5)\n",
    "arr9[arr9>5]=5\n",
    "print(arr9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>pre_e2</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "pre_e2 results: All test cases passed!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"pre_e2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**exercise3:** Construct pandas.Dataframe and other numpy exercises\n",
    "\n",
    "1. construct Dataframe object named `A` and `B` with pandas from `A.csv` and `B.csv`\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "        for A:\n",
    "        {'id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}, \n",
    "            'Beer_Name': {0: 'Honey Basil Amber', 1: 'Freedom Soho Red', 2: 'Jazz Beer Tarraco Amber', 3: 'Sanibel Red Island Ale', 4: 'Real McCoy Amber Ale', 5: 'River Otter Ale', 6: 'The Gentle Mongoose', 7: 'Arrow Point Amber', 8: 'River Otter Ale', 9: 'Rip Saw Red'}, \n",
    "            'Brew_Factory_Name': {0: 'Rude Hippo Brewing Company', 1: 'Freedom Brewery Ltd', 2: 'Tarraco Beer', 3: 'Point Ybel Brewing Company', 4: 'Mammoth Brewing Company', 5: 'Union Station Brewery', 6: 'Holy City Brewing', 7: 'Bainbridge Island Brewing Company', 8: 'Union Station Brewery', 9: 'Pints Brewing Co. .'}, \n",
    "            'Style': {0: 'American AmberRed Ale', 1: 'American AmberRed Ale', 2: 'American AmberRed Ale', 3: 'American AmberRed Ale', 4: 'American AmberRed Ale', 5: 'American AmberRed Ale', 6: 'American AmberRed Ale', 7: 'American AmberRed Ale', 8: 'American AmberRed Ale', 9: 'American AmberRed Ale'}, \n",
    "            'ABV': {0: 7.4, 1: 4.7, 2: 6.9, 3: 5.6, 4: 4.5, 5: 5.1, 6: 6.9, 7: 5.4, 8: 5.1, 9: 6.5}}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "        for B:\n",
    "        {'id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19}, \n",
    "            'Beer_Name': {0: 'Tongue Buckler - Imperial Red Ale', 1: 'Rude Hippo Honey Basil Amber', 2: 'Three Heads Buffalo Soul Jah Imperial Red Ale', 3: 'Freedom Soho Red', 4: 'Hop Around Imperial Red Ale', 5: 'Jazz Beer Tarraco Amber', 6: 'Marble Imperial Red Ale', 7: 'Point Ybel Sanibel Red Island Ale', 8: 'Smuttynose Kindest Find Imperial Red Ale', 9: 'Mammoth Real McCoy Amber Ale', 10: 'Rock Bottom Orland Park King of Hearts Imperial Red Ale', 11: 'Sacramento River Otter Ale', 12: 'Smuttynose Kindest Find Imperial Red Ale', 13: 'Holy City The Gentle Mongoose', 14: 'Brannon_s Deputation Imperial Red Ale', 15: 'Bainbridge Island Arrow Point Amber', 16: 'Red Dirt Imperial Red Ale', 17: 'Sacramento River Otter Ale', 18: 'AleSmith YuleSmith 40; Winter 41; Imperial Red Ale', 19: 'Pints Rip Saw Red'}, \n",
    "            'Brew_Factory_Name': {0: 'Ballast Point Brewing Company', 1: '18th Street Brewery', 2: 'Custom Brewcrafters', 3: 'Freedom', 4: 'Big Bay Brewing Co. .', 5: 'Ca l_Arenys - Cervezas Guineu', 6: 'Marble Brewery', 7: 'Point Ybel Brewing Company', 8: 'Smuttynose Brewing Company', 9: 'Mammoth Brewing Company', 10: 'Rock Bottom Orland Park', 11: 'Sacramento Brewing Company', 12: 'Smuttynose Brewing Company', 13: 'Holy City Brewing', 14: 'Brannon_s Pub and Brewery', 15: 'Bainbridge Island Brewing Company', 16: 'Wiley Roots Brewing Co', 17: 'Sacramento Brewing Company', 18: 'AleSmith Brewing Company', 19: 'Pints Brewing Company'}, \n",
    "            'Style': {0: 'American AmberRed Ale', 1: 'Amber Ale', 2: 'American Strong Ale', 3: 'Amber LagerVienna', 4: 'American AmberRed Ale', 5: 'Amber Ale', 6: 'American Strong Ale', 7: 'Irish Ale', 8: 'American AmberRed Ale', 9: 'Altbier', 10: 'American Strong Ale', 11: 'English Pale Ale', 12: 'American AmberRed Ale', 13: 'Amber Ale', 14: 'American Strong Ale', 15: 'Amber Ale', 16: 'American AmberRed Ale', 17: 'English Pale Ale', 18: 'American Strong Ale', 19: 'Amber Ale'}, \n",
    "            'ABV': {0: 10.0, 1: 7.4, 2: 9.2, 3: 4.7, 4: 9.0, 5: 6.9, 6: 9.0, 7: 5.6, 8: 8.5, 9: 4.5, 10: 7.6, 11: 5.5, 12: 8.5, 13: 6.9, 14: 8.79, 15: 5.4, 16: 8.2, 17: 5.5, 18: 8.5, 19: 5.9}}\n",
    "```\n",
    "\n",
    "2. construct numpy.array object `a3` as below.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "        a3:\n",
    "        0   1\n",
    "        1   3\n",
    "        2   5\n",
    "        3   7\n",
    "        ...\n",
    "        9   19\n",
    "```\n",
    "\n",
    "<font color='red'> Note: You need to create it according to the steps provided below; otherwise, some test cases may not pass. And the resulting seed should have a shape of (10,2). </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = pd.DataFrame.from_dict({'id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}, \n",
    "            'Beer_Name': {0: 'Honey Basil Amber', 1: 'Freedom Soho Red', 2: 'Jazz Beer Tarraco Amber', 3: 'Sanibel Red Island Ale', 4: 'Real McCoy Amber Ale', 5: 'River Otter Ale', 6: 'The Gentle Mongoose', 7: 'Arrow Point Amber', 8: 'River Otter Ale', 9: 'Rip Saw Red'}, \n",
    "            'Brew_Factory_Name': {0: 'Rude Hippo Brewing Company', 1: 'Freedom Brewery Ltd', 2: 'Tarraco Beer', 3: 'Point Ybel Brewing Company', 4: 'Mammoth Brewing Company', 5: 'Union Station Brewery', 6: 'Holy City Brewing', 7: 'Bainbridge Island Brewing Company', 8: 'Union Station Brewery', 9: 'Pints Brewing Co. .'}, \n",
    "            'Style': {0: 'American AmberRed Ale', 1: 'American AmberRed Ale', 2: 'American AmberRed Ale', 3: 'American AmberRed Ale', 4: 'American AmberRed Ale', 5: 'American AmberRed Ale', 6: 'American AmberRed Ale', 7: 'American AmberRed Ale', 8: 'American AmberRed Ale', 9: 'American AmberRed Ale'}, \n",
    "            'ABV': {0: 7.4, 1: 4.7, 2: 6.9, 3: 5.6, 4: 4.5, 5: 5.1, 6: 6.9, 7: 5.4, 8: 5.1, 9: 6.5}})\n",
    "B = pd.DataFrame.from_dict({'id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19}, \n",
    "            'Beer_Name': {0: 'Tongue Buckler - Imperial Red Ale', 1: 'Rude Hippo Honey Basil Amber', 2: 'Three Heads Buffalo Soul Jah Imperial Red Ale', 3: 'Freedom Soho Red', 4: 'Hop Around Imperial Red Ale', 5: 'Jazz Beer Tarraco Amber', 6: 'Marble Imperial Red Ale', 7: 'Point Ybel Sanibel Red Island Ale', 8: 'Smuttynose Kindest Find Imperial Red Ale', 9: 'Mammoth Real McCoy Amber Ale', 10: 'Rock Bottom Orland Park King of Hearts Imperial Red Ale', 11: 'Sacramento River Otter Ale', 12: 'Smuttynose Kindest Find Imperial Red Ale', 13: 'Holy City The Gentle Mongoose', 14: 'Brannon_s Deputation Imperial Red Ale', 15: 'Bainbridge Island Arrow Point Amber', 16: 'Red Dirt Imperial Red Ale', 17: 'Sacramento River Otter Ale', 18: 'AleSmith YuleSmith 40; Winter 41; Imperial Red Ale', 19: 'Pints Rip Saw Red'}, \n",
    "            'Brew_Factory_Name': {0: 'Ballast Point Brewing Company', 1: '18th Street Brewery', 2: 'Custom Brewcrafters', 3: 'Freedom', 4: 'Big Bay Brewing Co. .', 5: 'Ca l_Arenys - Cervezas Guineu', 6: 'Marble Brewery', 7: 'Point Ybel Brewing Company', 8: 'Smuttynose Brewing Company', 9: 'Mammoth Brewing Company', 10: 'Rock Bottom Orland Park', 11: 'Sacramento Brewing Company', 12: 'Smuttynose Brewing Company', 13: 'Holy City Brewing', 14: 'Brannon_s Pub and Brewery', 15: 'Bainbridge Island Brewing Company', 16: 'Wiley Roots Brewing Co', 17: 'Sacramento Brewing Company', 18: 'AleSmith Brewing Company', 19: 'Pints Brewing Company'}, \n",
    "            'Style': {0: 'American AmberRed Ale', 1: 'Amber Ale', 2: 'American Strong Ale', 3: 'Amber LagerVienna', 4: 'American AmberRed Ale', 5: 'Amber Ale', 6: 'American Strong Ale', 7: 'Irish Ale', 8: 'American AmberRed Ale', 9: 'Altbier', 10: 'American Strong Ale', 11: 'English Pale Ale', 12: 'American AmberRed Ale', 13: 'Amber Ale', 14: 'American Strong Ale', 15: 'Amber Ale', 16: 'American AmberRed Ale', 17: 'English Pale Ale', 18: 'American Strong Ale', 19: 'Amber Ale'}, \n",
    "            'ABV': {0: 10.0, 1: 7.4, 2: 9.2, 3: 4.7, 4: 9.0, 5: 6.9, 6: 9.0, 7: 5.6, 8: 8.5, 9: 4.5, 10: 7.6, 11: 5.5, 12: 8.5, 13: 6.9, 14: 8.79, 15: 5.4, 16: 8.2, 17: 5.5, 18: 8.5, 19: 5.9}})\n",
    "\n",
    "a1 = np.arange(10)# Create an array with 10 elements ranging from 0 to 9\n",
    "a2 = np.arange(20) # Create an array with 20 elements ranging from 0 to 19\n",
    "a2 =a2[a2%2==1]# Filter the odd numbers in a2 so that the elements of a2 are 1,3,5,...,19, there are 10 numbers\n",
    "# Intermediate code can be written to perform operations such as reshape()\n",
    "a3 = np.concatenate((a1, a2))  # Concatenate a1 and a2 to produce the resulting seeds object as shown in the markdown code block above\n",
    "a3=a3.reshape(2,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>pre_e3</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "pre_e3 results: All test cases passed!"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"pre_e3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise1: Define a rule-based EA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entity Alignmen:** Entity Alignment (EA) is an important task in the fields of Natural Language Processing (NLP) and Knowledge Graphs, with its primary objective being to map (correspond) entities from different knowledge graphs or data sources to equivalent entities in each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise Introduction:** In this exercise, you are required to use the Pandas library to read data from a CSV file and create the corresponding test dataset. In this experiment, we assume there are two knowledge bases, A and B, which store data only about beers, and the data is highly structured. Therefore, for the convenience of data reading, we will no longer provide the data in the form of knowledge graph triples but instead present the data in the form of relational tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** The first 5 rows of A and B are shown as below.\n",
    "\n",
    "A: \n",
    "id|Beer_Name|Brew_Factory_Name|Style|ABV\n",
    "------- | ------- | ------- | ------- | -------\n",
    "0 | Honey Basil Amber | Rude Hippo Brewing Company | American AmberRed Ale | 7.4\n",
    "1 | Freedom Soho Red | Freedom Brewery Ltd | American AmberRed Ale | 4.7\n",
    "2 | Jazz Beer Tarraco Amber | Tarraco Beer | American AmberRed Ale | 6.9\n",
    "3 | Sanibel Red Island Ale | Point Ybel Brewing Company | American AmberRed Ale | 5.6\n",
    "4 | Real McCoy Amber Ale | Mammoth Brewing Company | American AmberRed Ale | 4.5\n",
    "\n",
    "B:\n",
    "id | Beer_Name | Brew_Factory_Name | Style | ABV\n",
    "---|-----------|-------------------|-------|----\n",
    "0 | Tongue Buckler - Imperial Red Ale | Ballast Point Brewing Company | American AmberRed Ale | 10.0\n",
    "1 | Rude Hippo Honey Basil Amber | 18th Street Brewery | Amber Ale | 7.4\n",
    "2 | Three Heads Buffalo Soul Jah Imperial Red Ale | Custom Brewcrafters | American Strong Ale | 9.2\n",
    "3 | Freedom Soho Red | Freedom | Amber LagerVienna | 4.7\n",
    "4 | Hop Around Imperial Red Ale | Big Bay Brewing Co. . | American AmberRed Ale | 9.0\n",
    "\n",
    "$Entity_0$ in A is a `American AmberRed Ale`(Beer) named `Honey Basil Amber` produced by `Rude Hippo Brewing Company` whose `ABV` is 7.4.\n",
    "\n",
    "$Entity_1$ in B is a `Amber Ale`(Beer) named `Rude Hippo Honey Basil Amber` produced by `18th Street Brewery` whose `ABV` is 7.4.\n",
    "\n",
    "- Style: The only difference is that $Entity_1$ in B has omitted attributes.\n",
    "- Name: Same thing in different format.\n",
    "- Brew_Factory_Name: Rude Hippo Brewing Company and 18th Street Brewery refer to the same Brew Factory actually.\n",
    "- ABV: Exactly the same.\n",
    "\n",
    "Thus, $Entity_0$ in A and $Entity_1$ in B are actually the same entity in real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct an EA dataset from DataFrame A and DataFrame B.** If we look through all entities in A and B, we can find that:\n",
    "\n",
    "- $Entity_0$ in A and $Entity_1$ in B are the same.\n",
    "- $Entity_1$ in A and $Entity_3$ in B are the same.\n",
    "- $Entity_2$ in A and $Entity_5$ in B are the same.\n",
    "- $Entity_3$ in A and $Entity_7$ in B are the same.\n",
    "- ...\n",
    "\n",
    "We can use an numpy array named `seeds` to record the alignment results as:\n",
    "\n",
    "```python\n",
    "        0   1\n",
    "        1   3\n",
    "        2   5\n",
    "        3   7\n",
    "        ...\n",
    "        9   19\n",
    "```\n",
    "\n",
    "We can notice that `seeds` is identical to `a3` in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 1,  3],\n",
       "       [ 2,  5],\n",
       "       [ 3,  7],\n",
       "       [ 4,  9],\n",
       "       [ 5, 11],\n",
       "       [ 6, 13],\n",
       "       [ 7, 15],\n",
       "       [ 8, 17],\n",
       "       [ 9, 19]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = a3\n",
    "seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step1:** Define a function that inputs two strings and outputs their string Levenstein ratio as the similarity.(call `Levenshtein.ratio(str1, str2)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def string_sim(str1, str2):\n",
    "    return Levenshtein.ratio(str1,str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>ex1_q1</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "ex1_q1 results: All test cases passed!"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"ex1_q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step2:** Implement $model_{EA}$„ÄÇ\n",
    "\n",
    "given two entities $e_1=[p_1^1,p_2^1,...,p_n^1]$ and $e_2=[p_1^2,p_2^2,...,p_n^2]$ and a string similarity function $sim()$, $model_{EA}$ is defined as below.\n",
    "$$model_{EA}(e_1,e_2)=\\frac{1}{n}\\sum_{i=1}^n sim(p_i^1,p_i^2)$$\n",
    "\n",
    "Use the python language to implement this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                            0\n",
      "Beer_Name                     Honey Basil Amber\n",
      "Brew_Factory_Name    Rude Hippo Brewing Company\n",
      "Style                     American AmberRed Ale\n",
      "ABV                                         7.4\n",
      "Name: 0, dtype: object\n",
      "0.6666666666666666\n",
      "0.3098086124401914\n"
     ]
    }
   ],
   "source": [
    "def model_EA(e1, e2):\n",
    "    sims = [] # build a list to save similarities of all properties between e1 and e2\n",
    "    # traverse all properties(except `id` property) in e1,e2\n",
    "    for i in range(1,len(e1)) :\n",
    "        # calculate similarity of properties with similarity function `string_sim(str1,str2)`\n",
    "        #if type(e1[i])!=str:\n",
    "        #    continue\n",
    "        t=string_sim(str(e1[i]),str(e2[i]))\n",
    "        # append the calculated similarity to `sims`\n",
    "        sims.append(t)\n",
    "    # calculate the average similarities and return it\n",
    "    return (1/len(sims))*(sum(sims))\n",
    "\n",
    "e1 = A.iloc[0]\n",
    "e2 = B.iloc[1]\n",
    "print(e1)\n",
    "sim_of_entities = model_EA(e1, e2)\n",
    "print(sim_of_entities)\n",
    "model_EA(A.iloc[0], B.iloc[1])\n",
    "print(model_EA(A.iloc[0], B.iloc[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>ex1_q2</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "ex1_q2 results: All test cases passed!"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"ex1_q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise2: Calculate Hit@k of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step1:** obtain similarity matrix `mat`\n",
    "- type: numpy.array\n",
    "- shape: (len_A, len_B)\n",
    "- mat[i][j]: represents the similarity between $entity_i$ in A and $entity_j$ in B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mat[i][j] represents the similarity between entity i in A and entity j in B\n",
    "mat = np.ones((len(A),len(B)))\n",
    "for i in range(len(A)):\n",
    "    for j in range(len(B)):\n",
    "        mat[i][j]=model_EA(A.iloc[i], B.iloc[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>ex2_q1</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "ex2_q1 results: All test cases passed!"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"ex2_q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step2:** Calculate Hit@k\n",
    "\n",
    "Hit@k indicates whether the correct matching entity is included in the first k candidate entities. For example, there are the following data.\n",
    "\n",
    "entity|candidates(sorted by sim)\n",
    "-|-\n",
    "$a_1$|$b_2,b_1,b_3$\n",
    "$a_2$|$b_2,b_3,b_1$\n",
    "$a_3$|$b_1,b_2,b_3$\n",
    "\n",
    "The actual matching results are: $(a_1,b_1),(a_2,b_2),(a_3,b_3)$\n",
    "\n",
    "Then $hit@1=1/3=0.33$, because only the second row matches successfully in the first candidate entity; $hit@2=2/3=0.67$, because the second and first rows match successfully in the first two candidate entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define a function that, given the value of $k$, outputs the $hit@k$ of $model_{EA}$.\n",
    "\n",
    "Note: If you do not want to follow the belowing procedures in Prompt, you can try `np.argsort()`, which may bring you surprise for concise codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hit_k(mat, seeds, k=1):\n",
    "    # Iterate through each row of the array `seeds` and get seed `(l, r)`\n",
    "    # try to sort similarity array(mat[l]) of Entity l in A and record the corresponding indexes of each elements\n",
    "    # record the original indexes of top-k highest similarities, if r in these indexes, count += 1\n",
    "    # return count/len(seeds)\n",
    "    count=0\n",
    "    for l,r in seeds:\n",
    "        s=np.argsort(-mat[l],axis=0)\n",
    "        s=s[0:k]\n",
    "        if r in s:\n",
    "            count+=1\n",
    "    return count/len(seeds)\n",
    "hit_k(mat,seeds,k=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>ex2_q2</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "ex2_q2 results: All test cases passed!"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"ex2_q2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "labs01",
   "tests": {
    "ex1_q1": {
     "name": "ex1_q1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> string_sim('FanJu', 'fanju')==0.6\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> string_sim('ChenSibei', 'SibeiChen')==0.5555555555555556\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "ex1_q2": {
     "name": "ex1_q2",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model_EA(A.iloc[0], B.iloc[3])==0.3098086124401914\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model_EA(A.iloc[0], B.iloc[1])==0.6666666666666666\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "ex2_q1": {
     "name": "ex2_q1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> mat[0][0]==0.5850649350649351\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> mat[1][3]==0.7398785425101214\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "ex2_q2": {
     "name": "ex2_q2",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> hit_k(mat,seeds,k=1)==0.8\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> hit_k(mat,seeds,k=4)==1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> hit_k(mat,seeds,k=2)==0.9\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "pre_e1": {
     "name": "pre_e1",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> arr1.shape == (10,20) and arr1.sum() == 200\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr2.shape == (10,20) and arr2.sum() == 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr3[2] == 0.12693303650867852 and arr3.sum() == 314.15926535897927\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr4[15] == 0.5800569095711982 and arr4.sum() == 1.0000000000000013\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "pre_e2": {
     "name": "pre_e2",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> arr5.shape == (3,4) and arr5.sum() == 48\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr6.sum() == 19\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr7.sum() == 16\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr8.sum() == 3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr9.shape == (3,4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> arr9.sum() == 35\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "pre_e3": {
     "name": "pre_e3",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> A.iloc[0]['id']==0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> A.iloc[2]['Brew_Factory_Name']=='Tarraco Beer'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> a3.shape == (10,2) and a3[4,0] == 4 and a3[4,1] == 9 and int(sum(a1))==45\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
